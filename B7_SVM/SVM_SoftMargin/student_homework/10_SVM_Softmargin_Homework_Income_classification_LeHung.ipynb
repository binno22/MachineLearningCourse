{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# I. Lý thuyết (5 điểm)"
      ],
      "metadata": {
        "id": "KFUypJ-c-cED"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Điểm khác biệt chính giữa mô hình `SVM hard margin` và `SVM soft margin` là gì ?\n",
        "\n",
        "(A). SVM hard margin không chấp nhận các điểm dữ liệu nằm trong vùng margin. SVM soft margin chấp nhận một số điểm được phép nằm trong vùng margin.\n",
        "\n",
        "B. SVM soft margin không chấp nhận các điểm dữ liệu nằm trong vùng margin. SVM hard margin chấp nhận một số điểm được phép nằm trong vùng margin.\n",
        "\n",
        "C. SVM hard margin có độ rộng đường biên rộng hơn SVM soft margin \n",
        "\n",
        "D. SVM soft margin có độ rộng đường biên rộng hơn SVM hard margin"
      ],
      "metadata": {
        "id": "hkDGhWEj-lGA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Trong thuật toán `SVM soft margin` thì khoảng cách mà một điểm được phép lấn chiếm vào trong vùng margin bằng bao nhiêu?\n",
        "\n",
        "(A). $\\xi_i = |b+\\mathbf{w}^{\\intercal}\\mathbf{x}_i-y_i|$\n",
        "\n",
        "B. $\\xi_i = b+\\mathbf{w}^{\\intercal}\\mathbf{x}_i-y_i$\n",
        "\n",
        "C. $\\xi_i = y_i(b+\\mathbf{w}^{\\intercal}\\mathbf{x}_i)-1$\n",
        "\n",
        "D. $\\xi_i = 1-y_i(b+\\mathbf{w}^{\\intercal}\\mathbf{x}_i)$"
      ],
      "metadata": {
        "id": "U8qf_ZwU_W6i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Hàm mất mát của `SVM soft margin` có đặc điểm như thế nào ?\n",
        "\n",
        "A. Là hàm mất mát nhằm tối ưu độ rộng đường biên.\n",
        "\n",
        "B. Là hàm mất mát nhằm tối ưu mức độ lấn chiếm của các điểm dữ liệu vào vùng margin.\n",
        "\n",
        "C. Là hàm mất mát nhằm tối ưu hai thành phần: Độ rộng đường biên và mức độ lấn chiếm của các điểm dữ liệu vào vùng margin.\n",
        "\n",
        "(D). Cả ba phương án trên."
      ],
      "metadata": {
        "id": "ofrfo1mjCtVK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) Ý nghĩa của hàm feature mapping trong SVM là gì ?\n",
        "\n",
        "A. Là hàm biến đổi dữ liệu đầu vào $\\mathbf{x}$ sang không gian features mới thông qua một hàm $f(\\mathbf{x})$. Trong đó $f()$ có thể là `tractable` hoặc `intractable` form.\n",
        "\n",
        "B. Là hàm biến đổi dữ liệu đầu vào $\\mathbf{x}$ sang không gian features có số chiều nhỏ hơn.\n",
        "\n",
        "C. Là hàm biến đổi dữ liệu đầu vào $\\mathbf{x}$ sang không gian features có số chiều là vô hạn.\n",
        "\n",
        "(D). Là hàm biến đổi dữ liệu đầu vào $\\mathbf{x}$ sang không gian features thông qua một hàm $f(\\mathbf{x})$ dạng đa thức."
      ],
      "metadata": {
        "id": "S7ac7BsWChTi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5) Ý nghĩa của hàm kernel function trong SVM là gì ?\n",
        "\n",
        "A. Là hàm mapping từ không gian véc tơ sang không gian hàm số.\n",
        "\n",
        "B. Là hàm mapping từ không gian véc tơ sang không gian số thực.\n",
        "\n",
        "C. Là hàm mapping từ không gian véc tơ sang không gian số phức.\n",
        "\n",
        "(D.) Là hàm mapping từ không gian của hai véc tơ sang không gian tích vô hướng giữa hai véc tơ (còn được gọi là không gian Hilbert)."
      ],
      "metadata": {
        "id": "hFd6HxLQD6St"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6) Tại sao chúng ta có thể xác định được nhãn của một điểm ngay cả khi không thể xác định được phương trình của hàm feature mapping.\n",
        "\n",
        "A. Vì nhãn của một điểm dữ liệu có thể được xác định thông qua hàm loss function.\n",
        "\n",
        "(B) Vì nhãn của một điểm dữ liệu có thể được xác định thông qua hàm kernel function giữa điểm đó với các điểm thuộc tập support vectors.\n",
        "\n",
        "C. Vì nhãn của một điểm dữ liệu có thể được xác định thông qua phương trình đường biên.\n",
        "\n",
        "D. Cả ba đáp án trên."
      ],
      "metadata": {
        "id": "okMeR3KfDS62"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7) Hàm kernel function dạng `linear` function có dạng như thế nào ?\n",
        "\n",
        "A. $K(\\mathbf{x}_1, \\mathbf{x}_2) = \\text{tanh}(\\gamma \\mathbf{x}_1^{\\intercal}\\mathbf{x}_2+r)$\n",
        "\n",
        "(B). $K(\\mathbf{x}_1, \\mathbf{x}_2) = \\mathbf{x}_1^{\\intercal}\\mathbf{x}_2$\n",
        "\n",
        "C. $K(\\mathbf{x}_1, \\mathbf{x}_2) = \\exp({-\\gamma||\\mathbf{x}_1}-\\mathbf{x}_2||_2^2)$\n",
        "\n",
        "D. $K(\\mathbf{x}_1, \\mathbf{x}_2) = (\\gamma \\mathbf{x}_1^{\\intercal}\\mathbf{x}_2+r)^d$\n"
      ],
      "metadata": {
        "id": "bL3GSNvTD-5a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8) Hàm kernel function dạng `poly` function có dạng như thế nào ?\n",
        "\n",
        "A. $K(\\mathbf{x}_1, \\mathbf{x}_2) = \\text{tanh}(\\gamma \\mathbf{x}_1^{\\intercal}\\mathbf{x}_2+r)$\n",
        "\n",
        "B. $K(\\mathbf{x}_1, \\mathbf{x}_2) = \\mathbf{x}_1^{\\intercal}\\mathbf{x}_2$\n",
        "\n",
        "C. $K(\\mathbf{x}_1, \\mathbf{x}_2) = \\exp({-\\gamma||\\mathbf{x}_1}-\\mathbf{x}_2||_2^2)$\n",
        "\n",
        "(D). $K(\\mathbf{x}_1, \\mathbf{x}_2) = (\\gamma \\mathbf{x}_1^{\\intercal}\\mathbf{x}_2+r)^d$\n",
        "\n"
      ],
      "metadata": {
        "id": "FRqijemVEWCG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9) Hàm kernel function dạng `Gaussian rbf` function có dạng như thế nào ?\n",
        "\n",
        "A. $K(\\mathbf{x}_1, \\mathbf{x}_2) = \\text{tanh}(\\gamma \\mathbf{x}_1^{\\intercal}\\mathbf{x}_2+r)$\n",
        "\n",
        "B. $K(\\mathbf{x}_1, \\mathbf{x}_2) = \\mathbf{x}_1^{\\intercal}\\mathbf{x}_2$\n",
        "\n",
        "(C). $K(\\mathbf{x}_1, \\mathbf{x}_2) = \\exp({-\\gamma||\\mathbf{x}_1}-\\mathbf{x}_2||_2^2)$\n",
        "\n",
        "D. $K(\\mathbf{x}_1, \\mathbf{x}_2) = (\\gamma \\mathbf{x}_1^{\\intercal}\\mathbf{x}_2+r)^d$\n",
        "\n"
      ],
      "metadata": {
        "id": "NJrtylrhEqzj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10) Hàm kernel function nào sẽ tương ứng với hàm feature mapping là một đa thức có bậc là vô hạn ?\n",
        "\n",
        "(A). Gaussian RBF\n",
        "\n",
        "B. Poly function\n",
        "\n",
        "C. Linear function\n",
        "\n",
        "D. Sigmoid function\n"
      ],
      "metadata": {
        "id": "LXIKISsLFTHm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# II. Thực hành (5 điểm)\n",
        "\n",
        "Từ bộ dữ liệu [income_classification](https://drive.google.com/drive/folders/13STuE4IF_gukgw57El-jfjIKg8uM6L7O?usp=sharing) hãy thực hiện huấn luyện và grid search mô hình trên tập train và đánh giá mô hình trên tập validation dựa trên thuật toán SVM. Biết rằng thông tin về bộ dữ liệu tham khảo [Income classification](https://www.kaggle.com/competitions/ml-hands-on-python-kaggle-01/data)."
      ],
      "metadata": {
        "id": "3x3IsOdF-gwN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "vrw6OJ7aTugO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Atj9wFxZFGEO"
      },
      "source": [
        "import pandas as pd\n",
        "from IPython.display import Markdown, display\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "import seaborn as sns\n",
        "from sklearn import svm\n",
        "from sklearn import tree\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train=pd.read_csv('/content/drive/MyDrive/Colab Notebooks/income_classification/train.csv')\n",
        "df_test= pd.read_csv('/content/drive/MyDrive/Colab Notebooks/income_classification/test.csv')"
      ],
      "metadata": {
        "id": "dxUrM4R0Fx2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.shape"
      ],
      "metadata": {
        "id": "39AJ0w4bGXk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "id": "wleoRiQEGcVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "col_names = df_train.columns\n",
        "\n",
        "col_names"
      ],
      "metadata": {
        "id": "4NbysOiCGiVR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.columns = df_train.columns.str.strip()"
      ],
      "metadata": {
        "id": "OebaDeDuGqHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.columns"
      ],
      "metadata": {
        "id": "eNpqEBGAGxN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.info()"
      ],
      "metadata": {
        "id": "6zcjxKwgHI5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.replace({'?' : np.nan}, inplace=True)"
      ],
      "metadata": {
        "id": "AdiEvc_nHTiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.isna().sum()"
      ],
      "metadata": {
        "id": "vU1GjSgGHs38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train[df_train['job'].isna()]"
      ],
      "metadata": {
        "id": "i-FukBjGH_nF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['job'].dropna().unique()"
      ],
      "metadata": {
        "id": "dTs5KZWjIGU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "df_train['job'] = df_train['job'].apply(lambda x: random.choice(df_train['job'].dropna().unique()) if pd.isna(x) else x)\n",
        "df_train['work_type'] = df_train['work_type'].apply(lambda x: random.choice(df_train['work_type'].dropna().unique()) if pd.isna(x) else x)"
      ],
      "metadata": {
        "id": "CTvhPQJNIStN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['job'].value_counts()"
      ],
      "metadata": {
        "id": "tnzyLQOdIdjK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "df_train[['ethnicity', 'nationality']].value_counts().head(10)"
      ],
      "metadata": {
        "id": "vr5Do0N2IqCY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['nationality'].fillna('US', inplace= True)"
      ],
      "metadata": {
        "id": "M0EJa8utLr1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.isna().sum()"
      ],
      "metadata": {
        "id": "bTuWfEB9LvvP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "file test\n"
      ],
      "metadata": {
        "id": "ftF0TuzSL2XY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.replace({'?': np.nan}, inplace=True)"
      ],
      "metadata": {
        "id": "-jlSvc7KL2GI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test['job'] = df_test['job'].apply(lambda x: random.choice(df_test['job'].dropna().unique()) if pd.isna(x) else x)\n",
        "df_test['work_type'] = df_test['work_type'].apply(lambda x: random.choice(df_test['work_type'].dropna().unique()) if pd.isna(x) else x)\n",
        "df_test['nationality'].fillna('US', inplace= True)"
      ],
      "metadata": {
        "id": "f4eltt-dL9SO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.isna().sum()"
      ],
      "metadata": {
        "id": "yB50WPrhMFai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target = df_train['target_income']\n",
        "data = df_train.drop(columns='target_income')"
      ],
      "metadata": {
        "id": "b3L1IMCDMN2V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.describe(include=[object])"
      ],
      "metadata": {
        "id": "hJ84FafYOPZd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[['total_education_yrs', 'education']].value_counts()"
      ],
      "metadata": {
        "id": "vHNdDHY4OXXD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[['marital_state', 'status']].value_counts()"
      ],
      "metadata": {
        "id": "AsBrQPc1OZZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.drop(columns=['education', 'marital_state', 'ethnicity'], inplace= True)\n",
        "df_test.drop(columns=['education', 'marital_state', 'ethnicity'], inplace= True)"
      ],
      "metadata": {
        "id": "ce38NkJEObux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cate_cols = data.select_dtypes(include='object')\n",
        "name_cate_cols = cate_cols.columns\n",
        "name_cate_cols"
      ],
      "metadata": {
        "id": "8oPtIgqBOvlk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "#from sklearn.experimental import enable_hist_gradient_boosting\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "metadata": {
        "id": "wR1LuFA8MwY9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import set_config\n",
        "set_config(display=\"diagram\")"
      ],
      "metadata": {
        "id": "4JBDqJqXMzrT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "pipeline"
      ],
      "metadata": {
        "id": "f-21QrbNNEIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocessor = ColumnTransformer([('cat_preprocess', OrdinalEncoder(), name_cate_cols)],\n",
        "                                remainder='passthrough', sparse_threshold=0)"
      ],
      "metadata": {
        "id": "EVBA-Op5M1dK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_encoded = preprocessor.fit_transform(data)"
      ],
      "metadata": {
        "id": "snEf31uDM8Z3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_corr = pd.DataFrame(data_encoded, columns= data.columns)\n",
        "df_corr['target'] = target\n",
        "corr = df_corr.corr()\n",
        "corr.style.background_gradient(cmap='coolwarm')"
      ],
      "metadata": {
        "id": "wJZ4-pKuPPrs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model\n"
      ],
      "metadata": {
        "id": "nMGXoELDPYvj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = svm.SVC()\n",
        "model"
      ],
      "metadata": {
        "id": "ZgsbRHWvPRCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for parameter in model.get_params():\n",
        "    print(parameter)"
      ],
      "metadata": {
        "id": "bQxjeIX3Pdkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "parameters = {\n",
        "            'kernel':['rbf', 'sigmoid'],\n",
        "            'C':[0.01, 1, 100],\n",
        "\n",
        "}\n",
        "\n",
        "result =GridSearchCV(model, parameters, cv= 2, n_jobs =2, scoring='accuracy',return_train_score=True)\n",
        "result.fit(data_encoded,target)"
      ],
      "metadata": {
        "id": "19EXcRy3cJOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result.best_params_"
      ],
      "metadata": {
        "id": "elMpcPp9gCDW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_results=pd.DataFrame(result.cv_results_)"
      ],
      "metadata": {
        "id": "WsIOKMIlgOTg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv_results[['params', 'mean_test_score']]"
      ],
      "metadata": {
        "id": "NHqvO7V5gVWu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}