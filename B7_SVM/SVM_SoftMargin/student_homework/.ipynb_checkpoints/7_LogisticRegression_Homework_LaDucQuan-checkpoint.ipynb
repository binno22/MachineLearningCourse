{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_NWsO-83PoU9"
   },
   "source": [
    "# I. Lý thuyết\n",
    "\n",
    "Đáp án lựa chọn được tô đậm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5SBg7TzVPrFY"
   },
   "source": [
    "1) Xác suất dự báo của mô hình hồi qui Logistic được xây dựng dựa trên hàm Sigmoid có công thức như thế nào ?\n",
    "\n",
    "A. $\\sigma(x) = \\frac{1}{1+e^{-x}}$\n",
    "\n",
    "B. $\\sigma(x) = \\frac{e^{x}}{1+e^{x}}$\n",
    "\n",
    "C. $\\sigma(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}}$\n",
    "\n",
    "**D. Cả A và B**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ktUs4NoqQWju"
   },
   "source": [
    "2) Phát biểu nào sau đây là chính xác về hàm Sigmoid\n",
    "\n",
    "A. Hàm Sigmoid là hàm số đồng biến.\n",
    "\n",
    "B. Hàm Sigmoid là hàm lồi.\n",
    "\n",
    "C. Hàm Sigmoid có giá trị nằm trong khoảng (0, 1).\n",
    "\n",
    "**D. Cả ba đáp án trên.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PNueGbpqRL3F"
   },
   "source": [
    "3) Lý do Linear Regression thường không được sử dụng trong bài toán phân loại là gì ?\n",
    "\n",
    "A. Vì các giá trị dự báo có thể nằm ngoài khoảng (0, 1).\n",
    "\n",
    "B. Hồi qui Linear Regression không có đường biên phân chia.\n",
    "\n",
    "C. Mô hình dễ nhạy cảm với outliers khiến các dự báo bị sai.\n",
    "\n",
    "**D. Đáp án A và C**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qf8IYbE6c-3Q"
   },
   "source": [
    "4) Nếu chọn ngưỡng xác suất là 0.5 để quyết định nhãn dự báo thì đường biên phân chia của hồi qui Logistic là gì ?\n",
    "\n",
    "A. Một đường thẳng có phương trình $y=ax+b$\n",
    "\n",
    "**B. Một siêu phẳng có phương trình $\\mathbf{w}^{\\intercal}\\mathbf{x} = 0$**\n",
    "\n",
    "C. Một hình cầu. \n",
    "\n",
    "D. Một đường biên có quĩ đạo ellipse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JKw5fHsHezA5"
   },
   "source": [
    "5) Trong hồi qui Logistic tỷ lệ Odd Ratio được xác định như sau:\n",
    "\n",
    "$$\\text{Odd Ratio} = \\frac{P(y=1|\\mathbf{x}; \\mathbf{w})}{P(y=0|\\mathbf{x}; \\mathbf{w})} = \\frac{P(y=1|\\mathbf{x}, \\mathbf{w})}{1-P(y=1|\\mathbf{x}, \\mathbf{w})} = e^{\\mathbf{w}^{\\intercal}\\mathbf{x}}$$\n",
    "\n",
    "Tỷ lệ này có ý nghĩa như thế nào?\n",
    "\n",
    "A. Odd ratio là 1 chỉ số đo lường tỷ lệ xác suất giữa trường hợp _tích cực_ và _tiêu cực_ được dự báo từ mô hình hồi quy logistic.\n",
    "\n",
    "B. Căn cứ vào Odd Ratio, ta nhận biết được xác suất _tích cực_ hay _tiêu cực_ lớn hơn. \n",
    "\n",
    "C. Odd ratio càng lớn thì khả năng dự đoán có nhãn tích cực (positive) càng cao. Ngược lại, Odd ratio càng nhỏ thì khả năng dự đoán có nhãn tiêu cực (negative) càng cao.\n",
    "\n",
    "**D. Cả ba đáp án trên.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1jx0Qu6ehir7"
   },
   "source": [
    "6) Tại sao chúng ta không sử dụng hàm loss function là MSE (Mean Square Error) cho hồi qui Logistic?\n",
    "\n",
    "A. Vì hàm Loss Function MSE có chi phí tính toán lớn.\n",
    "\n",
    "B. Vì hàm Loss Function MSE không phải là một hàm lồi nên quá trình hội tụ tới nghiệm là global optimum khó khăn.\n",
    "\n",
    "C. Vì hàm Loss Function MSE không thể tính được đạo hàm bậc nhất.\n",
    "\n",
    "**(Sai) D. Vì hàm Loss Function MSE không thể đo được sai số giữa xác suất dự báo với nhãn 0, 1.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fAzkcPjnhWv2"
   },
   "source": [
    "7) Đạo hàm của hàm Sigmoid có giá trị như thế nào ?\n",
    "\n",
    "A. $\\sigma(x)' = \\tanh(x)(1-\\sigma(x))$\n",
    "\n",
    "**B. $\\sigma(x)' = \\sigma(x)(1-\\sigma(x))$**\n",
    "\n",
    "C. $\\sigma(x)' = \\sigma(x)^2(1-\\sigma(x))$\n",
    "\n",
    "D. $\\sigma(x)' = \\sigma(x)(1-\\sigma(x))^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F1RdfbbwjnSp"
   },
   "source": [
    "8) Phương pháp nào thường được sử dụng để tìm nghiệm cho hồi qui Logistic?\n",
    "\n",
    "**A. Sử dụng phương pháp _hạ dốc_ (_gradient descent_).**\n",
    "\n",
    "B. Đạo hàm bậc nhất.\n",
    "\n",
    "C. Sử dụng công thức Newton để tìm nghiệm.\n",
    "\n",
    "D. Sử dụng khai triển Taylor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BlyiewhomCXv"
   },
   "source": [
    "9) Hàm loss function Cross Entropy có dạng như thế nào ? Biết rằng trong công thức bên dưới thì $y_i$ là nhãn và $\\hat{y_i} = p(y=1|\\mathbf{x}_i; \\mathbf{w})$:\n",
    "\n",
    "A. $\\mathcal{L}(\\mathbf{w}) = \\sum_{i=1}^n [y_i\\log(\\hat{y_i}) + (1-y_i)\\log{(1-\\hat{y_i})}]$\n",
    "\n",
    "**B. $\\mathcal{L}(\\mathbf{w}) = -\\sum_{i=1}^n [y_i\\log(\\hat{y_i}) + (1-y_i)\\log{(1-\\hat{y_i})}]$**\n",
    "\n",
    "C. $\\mathcal{L}(\\mathbf{w}) = \\sum_{i=1}^n y_i\\log(\\frac{y_i}{\\hat{y_i}})$\n",
    "\n",
    "D. $\\mathcal{L}(\\mathbf{w}) = \\sum_{i=1}^n -(1-\\hat{y_i})^{\\gamma}\\log(\\hat{y_i})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tKVDn_s9owz5"
   },
   "source": [
    "10) Phát biểu nào sau đây là đúng về hàm mất mát Cross Entropy?\n",
    "\n",
    "A. Đo lường khoảng cách giữa phân phối xác suất thực tế và phân phối xác suất dự báo.\n",
    "\n",
    "B. Đo lường độ chính xác của mô hình.\n",
    "\n",
    "C. Đo lường sai số của mô hình.\n",
    "\n",
    "**D. Đo lường mức độ giống nhau giữa phân phối xác suất thực tế và phân phối xác suất dự báo.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-qSljebopi1s"
   },
   "source": [
    "# II. Thực hành"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bYEbW95SpnGi"
   },
   "source": [
    "Từ bộ dữ liệu iris về thông tin kích thước của các loài hoa với:\n",
    "\n",
    "- X là dữ liệu đầu vào gồm 4 biến: `'sepal length (cm)',\n",
    "  'sepal width (cm)',\n",
    "  'petal length (cm)',\n",
    "  'petal width (cm)'`\n",
    "- y các nhãn tương ứng với: `{0: 'setosa', 1: 'versicolor', 2: 'virginica'}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ps2-4-AXp31N",
    "outputId": "a194c139-b232-4ca4-eb1b-b249248dbf2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape của X ban đầu:  (150, 4)\n",
      "Shape của X và y sau khi đã thêm:  (150, 5) (150,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "data = load_iris()\n",
    "\n",
    "X = data['data']\n",
    "y = data['target']\n",
    "\n",
    "print(\"Shape của X ban đầu: \",X.shape)\n",
    "\n",
    "#tạo một ma trận cột toàn giá trị 1 để thêm vào ma trận X\n",
    "one_col = np.ones((X.shape[0],1))\n",
    "#Thêm phần tử 1 vào mỗi dòng của X \n",
    "X = np.concatenate((one_col,X), axis = 1)\n",
    "\n",
    "print(\"Shape của X và y sau khi đã thêm: \", X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gg419ojerx43"
   },
   "source": [
    "1) Thực hiện phân chia tập train/test theo tỷ lệ 80:20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ENTCrv-Or4ca",
    "outputId": "dcee31b1-d154-4605-eeec-89413919ffc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 120\n",
      "test size: 30\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 78)\n",
    "\n",
    "print('train size: {}'.format(len(x_train)))\n",
    "print('test size: {}'.format(x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C-5sguyNpwgU"
   },
   "source": [
    "2) Hãy viết hàm Cross Entropy tính toán loss function với đầu vào là nhãn $y$ và dự báo xác suất $\\hat{y}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SxCvzGdhrAsr"
   },
   "outputs": [],
   "source": [
    "def cross_entropy(y, y_hat):\n",
    "  # y_hat = f(wT * x) là tỷ lệ mà kết quả dự báo mang nhãn y\n",
    "  # y[i] có giá trị trong 0, 1, 2\n",
    "  res = 0\n",
    "  for i in range(len(y)):\n",
    "    res -= y[i] * np.log(y_hat[i][y[i]])\n",
    "  return res "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QtkbxrUSq9qQ"
   },
   "source": [
    "3) Hãy viết hàm tính toán giá trị gradient của hàm loss function theo $\\mathbf{w}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lVlhPaGbuk04"
   },
   "outputs": [],
   "source": [
    "def sigmoid(s):\n",
    "  return 2 / (1 + np.exp(-s)) #vì có ba class, min = 0, max = 2, nên thay số 1 trên tử số của hàm sigmoid thành số 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ov9qyYL5rKT4"
   },
   "outputs": [],
   "source": [
    "#giá trị gradient cho mảng w nhiều phần tử (trong bài này là 4)\n",
    "def gradient(w, X, y, alpha): #gradient tại một điểm Xi, yi cho w\n",
    "  #gradient = alpha * xi * (yi - yi_hat) for i in range (n) với n là số quan sát \n",
    "  #yi_hat   = f(wT * xi)\n",
    "  y_hat = sigmoid(np.dot(w.T, X))\n",
    "  res = []\n",
    "  for i in range(len(X)):\n",
    "    res.append(alpha * (y - y_hat) * X[i])  \n",
    "  return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mf9EqLDwrLOQ"
   },
   "source": [
    "4) Khởi tạo giá trị ban đầu của véc tơ trọng số $\\mathbf{w}$ và thực hiện huấn luyện mô hình trên tập train theo phương pháp cập nhật gradient descent với learning rate là $0.001$ với 200 vòng lặp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AiUrPIFIrlWS",
    "outputId": "4ee02296-5249-443d-bb8b-37385fc70c46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.37291318 -1.15670639 -0.72053745  1.88685511  1.15831845]\n"
     ]
    }
   ],
   "source": [
    "#khởi tạo giá trị ban đầu của vector w (1 vector có X.shape[1] = 4 phần tử, tương ứng 4 cột trong X)\n",
    "w = np.random.random(x_train.shape[1]) \n",
    "\n",
    "def logistic_model(X, y, w_init, learning_rate = 1e-3, n_its = 200):\n",
    "  N_rows = X.shape[0]\n",
    "  w  = w_init\n",
    "  for count in range(n_its):\n",
    "    for i in range(N_rows):\n",
    "      w = w + gradient(w, X[i], y[i], alpha = learning_rate) \n",
    "  return w       \n",
    "\n",
    "w = logistic_model(x_train, y_train, w)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j3wvtppxrkc0"
   },
   "source": [
    "5) Dự báo mô hình cho tập test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UrKYQqVMr8_D",
    "outputId": "236ab9a2-b57e-4850-ecf0-3d91ae4ea720"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tỷ lệ phân loại đúng trên tập test:  93.33%\n"
     ]
    }
   ],
   "source": [
    "y_hat = np.round_(sigmoid(np.dot(x_test, w.T)), decimals = 0)\n",
    "\n",
    "cnt = sum(y_hat == y_test)\n",
    "pct = \"{:.2%}\".format(cnt / len(y_test))\n",
    "print('Tỷ lệ phân loại đúng trên tập test: ', pct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "utXrBkV5_rJS"
   },
   "source": [
    "### Mở rộng\n",
    "\n",
    "sử dụng softmax function để phân loại với bài toán có 3 class <br>\n",
    "tham khảo: https://machinelearningcoban.com/2017/02/17/softmax/#-softmax-function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8oLMlyfFBI-b"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N_n3_NpG-ATl"
   },
   "outputs": [],
   "source": [
    "#tạo ma trận one hot encode đối với biến train để thực hiện softmax regression\n",
    "ohe = OneHotEncoder(sparse=False).fit(np.reshape(y_train, (len(y_train), 1))) \n",
    "y_train_binary = ohe.transform(np.reshape(y_train, (len(y_train), 1)))\n",
    "\n",
    "#hàm softmax\n",
    "def softmax(z):\n",
    "  e_Z = np.exp(z)\n",
    "  return (e_Z.T / e_Z.sum(axis = 1)).T #softmax của xi * w.T có shape là (1, 3), tính tổng các phần tử theo từng hàng nên axis = 1\n",
    "\n",
    "#softmax regression \n",
    "def softmax_regression(X, y, w_init, learning_rate = 1e-3, n_its = 200):\n",
    "  w = w_init\n",
    "  n_rows = X.shape[0]\n",
    "  for it in range(n_its): #lặp lại việc học n_its lần\n",
    "    for i in range(n_rows): #lặp lại việc duyệt của bộ dữ liệu với n_rows quan sát\n",
    "      xi = X[i].reshape(1, len(X[i])) #X là vector dòng, ở đây với 4 biến independent thì shape là 1,4\n",
    "      yi = y[i].reshape(1, len(y[i])) #y là vector dòng, có 3 class, shape là 1,3 \n",
    "      ai = softmax(xi.dot(w.T))  #ma trận dự đoán softmax(w.T * X)\n",
    "      w = w + learning_rate * (y[i] - ai).T.dot(xi)\n",
    "  return w\n",
    "\n",
    "#khởi tạo giá trị ban đầu của w sao cho softmax(w.T * X) có cùng shape với Y = (n_rows, 3 classes)\n",
    "w = np.random.random((3, x_train.shape[1])) \n",
    "w = softmax_regression(x_train, y_train_binary, w)\n",
    "\n",
    "def pred(W, X): #hàm dự đoán #C: số class, n: số dòng/số dữ liệu quan sát, m: số cột/số biến độc lập \n",
    "  #W có shape (C, m)\n",
    "  #X có shape (n, m)\n",
    "  #Y và A (Yhat) có shape (n, C)\n",
    "  A = softmax(X.dot(W.T))\n",
    "  return A.argmax(axis = 1) #chọn chỉ số của giá trị lớn nhất của từng dòng\n",
    "\n",
    "y_hat_sm = pred(w, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t0yAQdMKBnuB",
    "outputId": "ff960fda-df13-4707-dcf3-ea5cc621c120"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tỷ lệ phân loại đúng trên tập test:  93.33%\n"
     ]
    }
   ],
   "source": [
    "cnt = sum(y_hat_sm == y_test)\n",
    "pct = \"{:.2%}\".format(cnt / len(y_test))\n",
    "print('Tỷ lệ phân loại đúng trên tập test: ', pct)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
