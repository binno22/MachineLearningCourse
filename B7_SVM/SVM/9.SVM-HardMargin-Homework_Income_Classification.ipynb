{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# I. Lý thuyết (8 Câu, mỗi câu 0.625 điểm)"],"metadata":{"id":"Tg9j3F1fv9ps"}},{"cell_type":"markdown","source":["1) Khái niệm _phân chia tuyến tính_ (_linearly separable_) trong _SVM_ có nghĩa là gì ?\n","\n","A. Tồn tại một _siêu phẳng_ (_hyperplane_) phân chia đúng hoàn toàn các điểm dữ liệu về hai nhãn.\n","\n","B. Tồn tại một _siêu phẳng_ (_hyperplane_) phân chia đúng một phần các điểm dữ liệu về hai nhãn.\n","\n","C. Tồn tại một _đường thẳng_ phân chia đúng hoàn toàn các điểm dữ liệu về hai nhãn.\n","\n","D. Tồn tại một _đường thẳng_ phân chia đúng một phần các điểm dữ liệu về hai nhãn."],"metadata":{"id":"Ng5Wxf1cx6wi"}},{"cell_type":"markdown","source":["2) Thiết lập đầu vào và giả định của bài toán Hard Margin SVM là gì ?\n","\n","A. Bộ dữ liệu training $\\mathcal{D} = \\{(\\mathbf{x}_i, y_i)\\}_{i=1}^N$ trong đó nhãn $y_i \\in \\{-1, 1\\}$. Hai nhãn dữ liệu là hoàn toàn _phân chia tuyến tính_ (_linearly separable_).\n","\n","B. Bộ dữ liệu training $\\mathcal{D} = \\{(\\mathbf{x}_i, y_i)\\}_{i=1}^N$ trong đó nhãn $y_i \\in \\{0, 1\\}$. Hai nhãn dữ liệu là hoàn toàn _phân chia tuyến tính_ (_linearly separable_).\n","\n","C. Bộ dữ liệu training $\\mathcal{D} = \\{(\\mathbf{x}_i, y_i)\\}_{i=1}^N$ trong đó nhãn $y_i \\in \\{-1, 1\\}$.\n","\n","D. Bộ dữ liệu training $\\mathcal{D} = \\{(\\mathbf{x}_i, y_i)\\}_{i=1}^N$ trong đó nhãn $y_i \\in \\{0, 1\\}$."],"metadata":{"id":"BvFHZa0mwFA_"}},{"cell_type":"markdown","source":["3) Khái niệm margin của đường biên phân chia trong thuật toán SVM là gì ?\n","\n","A. Là độ rộng của đường biên phân chia được tính từ khoảng cách nhỏ nhất từ một điểm tới đường biên.\n","\n","B. Là độ rộng của đường biên phân chia được tính từ khoảng cách nhỏ nhất từ các điểm thuộc mỗi nhãn tới đường biên. Khoảng cách này bằng nhau tính từ phép chiếu vuông góc từ hai nhóm lên đường biên.\n","\n","C. Là khoảng cách lớn nhất từ một điểm tới đường biên.\n","\n","D. Là khoảng cách lớn nhất từ các điểm thuộc mỗi nhãn tới đường biên. Khoảng cách này bằng nhau tính từ phép chiếu vuông góc từ hai nhóm lên đường biên."],"metadata":{"id":"mgh5er_D0n82"}},{"cell_type":"markdown","source":["3) Để tìm ra được đường biên phân chia là _siêu phẳng_ phù hợp nhất thì mục tiêu tối ưu hóa của bài toán SVM là gì ?\n","\n","A. Tìm kiếm _siêu phẳng_ có độ rộng của margin là lớn nhất.\n","\n","B. Tìm kiếm _siêu phẳng_ có độ rộng của margin là nhỏ nhất.\n","\n","C. Tìm kiếm _siêu phẳng_ phân loại đúng mọi điểm của bộ dữ liệu huấn luyện.\n","\n","D. Tìm kiếm _siêu phẳng_ có phương trình tuyến tính."],"metadata":{"id":"knrpqBsPzt6S"}},{"cell_type":"markdown","source":["4) Độ rộng của đường biên phân chia được tính như thế nào trong bài toán phân loại hard margine SVM?\n","\n","A. $\\gamma = \\min_{i} \\frac{|y_i (\\mathbf{w}^{T}\\mathbf{x}_i+b)|}{||\\mathbf{w}||_2^2}$\n","\n","B. $\\gamma = \\frac{1}{||\\mathbf{w}||_2}$; Trong đó khoảng cách từ mọi điểm dữ liệu tới đường phân phải thỏa mãn $y_i (\\mathbf{w}^{T}\\mathbf{x}_i+b) = 1$\n","\n","C. $\\gamma = \\frac{1}{||\\mathbf{w}||_2^2}$;  Trong đó khoảng cách từ mọi điểm dữ liệu tới đường phân phải thỏa mãn $y_i (\\mathbf{w}^{T}\\mathbf{x}_i+b) = 1$\n","\n","D. $\\gamma = \\frac{|y_i (\\mathbf{w}^{T}\\mathbf{x}_i+b)|}{||\\mathbf{w}||_2}$\n"],"metadata":{"id":"rr4TModG27Zy"}},{"cell_type":"markdown","source":["5) Ý nghĩa của điều kiện ràng buộc trong bài toán tối đa hóa margin của đường biên phân chia trong SVM là gì ?\n","\n","A. $y_i (\\mathbf{w}^{T}\\mathbf{x}_i+b) \\geq 1, \\forall i=\\overline{1,N}$; mọi khoảng cách tới đường biên đều tối thiểu bằng 1.\n","\n","B. $y_i (\\mathbf{w}^{T}\\mathbf{x}_i+b) < 1, \\forall i=\\overline{1,N}$; mọi khoảng cách tới đường biên đều tối đa bằng 1.\n","\n","C. $ (\\mathbf{w}^{T}\\mathbf{x}_i+b) \\geq 1, \\forall i=\\overline{1,N}$; mọi khoảng cách tới đường biên đều tối thiểu bằng 1.\n","\n","D. $ (\\mathbf{w}^{T}\\mathbf{x}_i+b) < 1, \\forall i=\\overline{1,N}$; mọi khoảng cách tới đường biên đều tối đa bằng 1."],"metadata":{"id":"n6iHQPfC5jsH"}},{"cell_type":"markdown","source":["6) Phát biểu nào sau đây là đúng về bài toán primal và bài toán dual trong tối ưu hóa có điều kiện?\n","\n","A. Giá trị tối ưu của bài toán primal luôn tối thiểu bằng bài toán dual.\n","\n","B. Giá trị tối ưu của bài toán dual luôn tối thiểu bằng bài toán dual.\n","\n","C. Cả hai bài sẽ có chung nghiệm khi hệ điều kiện KKT (Karush-Kuhn-Tucker) được thỏa mãn.\n","\n","D. Đáp án A và C"],"metadata":{"id":"sih5qhno7mDy"}},{"cell_type":"markdown","source":["7) Khi giải bài toán tối ưu margin của đường biên phân chia trong SVM thì chúng ta thu được một tập điểm support vectors. Mục tiêu của tập này là gì ?\n","\n","A. Giúp tìm ra phương trình đường biên phân chia.\n","\n","B. Là những điểm gần nhất với đường biên phân chia.\n","\n","C. Là những điểm mà điều kiện ràng buộc xảy ra đẳng thức.\n","\n","D. Cả ba đáp án trên."],"metadata":{"id":"kpVQM6To8n0V"}},{"cell_type":"markdown","source":["8) Đâu là điều kiện trong hệ điều kiện KKT cho thấy trọng số $\\mathbf{w}$ chính là tổ hợp tuyến tính của các điểm nằm trên tập support vectors ?\n","\n","A. $\\nabla_{\\mathbf{w}} \\mathcal{L}(\\mathbf{w}, b, \\alpha) = w - \\sum_{i=1}^{N}\\alpha_iy_i \\mathbf{x}_i = 0$\n","\n","B. $\\nabla_{b} \\mathcal{L}(\\mathbf{w}, b, \\alpha) = \\sum_{i=1}^{N}\\alpha_i y_i  = 0$\n","\n","C. $\\alpha_i \\geq 0$\n","\n","D. $-y_i(\\mathbf{w}^{T}\\mathbf{x}+b) + 1 \\leq 0$"],"metadata":{"id":"9pIi4f3R-JuH"}},{"cell_type":"code","source":[],"metadata":{"id":"dJDyx9eLwBYn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# II. Thực hành"],"metadata":{"id":"A4ac_qPwwC8_"}},{"cell_type":"code","source":["from google.colab import drive\n","import os\n","\n","drive.mount('/content/drive')\n","os.chdir('drive/My Drive/Colab Notebooks/ML-Handson-With-Python')\n","!ls income_classification"],"metadata":{"id":"nU4JWougwGw6"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Atj9wFxZFGEO"},"source":["import pandas as pd\n","from IPython.display import Markdown, display\n","from sklearn.model_selection import train_test_split\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import roc_curve, auc\n","import numpy as np\n","from sklearn import metrics\n","import seaborn as sns\n","from sklearn import svm\n","from sklearn import tree\n","from sklearn.model_selection import cross_val_score\n","\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import roc_curve, auc\n","from sklearn.preprocessing import label_binarize\n","%  matplotlib inline\n","\n","from sklearn.model_selection import GridSearchCV"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# II. Thực hành (5 điểm)\n","\n","Từ bộ dữ liệu [income_classification](https://drive.google.com/drive/folders/13STuE4IF_gukgw57El-jfjIKg8uM6L7O?usp=sharing) hãy thực hiện huấn luyện mô hình trên tập train, đánh giá mô hình trên tập validation trên thuật toán SVM. Biết rằng thông tin về bộ dữ liệu tham khảo [Income classification](https://www.kaggle.com/competitions/ml-hands-on-python-kaggle-01/data).\n","\n","Để huấn luyện mô hình SVM thao khảo [SVM - example](https://phamdinhkhanh.github.io/deepai-book/ch_ml/SVM.html#vi-du-ve-bai-toan-svm)."],"metadata":{"id":"3kGNfQ17Cucd"}}]}