{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cNj0WtkDb_tw"
   },
   "source": [
    "# I. Thực hành"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V71cW0PFNWoO"
   },
   "source": [
    "Câu 1: Trong phương pháp bag-of-word thì mỗi một đoạn văn bản sẽ được biến đổi thành véc tơ đặc trưng như thế nào?\n",
    "\n",
    "\n",
    "A. Thành véc tơ tần suất của các từ xuất hiện trong từ điển.\n",
    "\n",
    "B. Thành véc tơ one-hot, từ nào xuất hiện trong văn bản thì có giá trị 1, trái lại nhận giá trị 0.\n",
    "\n",
    "C. Thành véc tơ tf-idf của từ.\n",
    "\n",
    "D. Thành một véc tơ trong không gian latent space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A. Thành véc tơ tần suất của các từ xuất hiện trong từ điển."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-bFR4B-1dv0_"
   },
   "source": [
    "Câu 2: Hai phương pháp `bigram` và `trigram` trong `bag-of-n-gram` sẽ mã hoá một văn bản như thế nào?\n",
    "\n",
    "A. `Bigram` sẽ ghép ba từ liên tiếp thành một token. `Trigram` sẽ ghép hai từ liên tiếp nhau thành một token.\n",
    "\n",
    "B. `Bigram` sẽ ghép hai từ liên tiếp thành một token. `Trigram` sẽ ghép ba từ liên tiếp nhau thành một token.\n",
    "\n",
    "C. `Bigram` sẽ chia mỗi một từ thành một token. `Trigram` sẽ ghép ba từ liên tiếp nhau thành một token.\n",
    "\n",
    "D. `Bigram` sẽ ghép hai từ bất kì trong khoảng cách gần thành một token. `Trigram` sẽ ghép ba từ liên tiếp trong khoảng cách gần thành một token."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B. Bigram sẽ ghép hai từ liên tiếp thành một token. Trigram sẽ ghép ba từ liên tiếp nhau thành một token."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uqu9GnNDfG_0"
   },
   "source": [
    "Câu 3: Giải thích ý nghĩa của chỉ số tf-idf được sử dụng để mã hoá các từ trong bộ văn bản. Một từ có tf-idf cao thì chứng tỏ điều gì?\n",
    "\n",
    "A. `tf-idf` là chỉ số mã hóa dựa trên độ dài của văn bản. Khi `tf-idf` cao chứng tỏ mức độ phổ biến của từ càng cao và ngược lại.\n",
    "\n",
    "B. `tf-idf` là chỉ số mã hóa dựa trên tần suất. Khi `tf-idf` cao chứng tỏ mức độ phổ biến của từ càng thấp và ngược lại.\n",
    "\n",
    "C. `tf-idf` nhằm đánh giá mức độ phổ biến của một từ dựa vào tần suất xuất hiện của từ trong một văn bản và tần suất các văn bản xuất hiện từ đó. Khi `tf-idf` cao chứng tỏ mức độ phổ biến của từ càng cao và ngược lại.\n",
    "\n",
    "D. `tf-idf` nhằm đánh giá mức độ quan trọng của một từ dựa vào tần suất xuất hiện của từ trong một văn bản và tần suất các văn bản xuất hiện từ đó. Khi `tf-idf` cao chứng tỏ mức độ quan trọng của từ càng cao và ngược lại."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D. tf-idf nhằm đánh giá mức độ quan trọng của một từ dựa vào tần suất xuất hiện của từ trong một văn bản và tần suất các văn bản xuất hiện từ đó. Khi tf-idf cao chứng tỏ mức độ quan trọng của từ càng cao và ngược lại."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qHA9G2YlNcnG"
   },
   "source": [
    "Câu 4: Kiến trúc nào thường được sử dụng để trích xuất đặc trưng (`Feature Extractor`) trong các bộ dữ liệu ảnh:\n",
    "\n",
    "A. Thuật toán SVM\n",
    " \n",
    "B. Thuật toán MLP\n",
    "\n",
    "C. Thuật toán CNN\n",
    "\n",
    "D. Thuật toán LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C. Thuật toán CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BA3ZjsDxPR8T"
   },
   "source": [
    "Câu 5: Tại sao chúng ta cần thực hiện các kĩ thuật chuẩn hóa dữ liệu như `Min-max Scaling`, `Standardization Scaling`, hoặc `Unit length Scaling` trên dữ liệu $\\mathbf{X}$ trước khi huấn luyện mô hình:\n",
    "\n",
    "A. Để đồng nhất đơn vị của các biến trước khi huấn luyện mô hình.\n",
    "\n",
    "B. Giúp các thuật toán ổn định hơn.\n",
    "\n",
    "C. Giảm chi phí tính toán.\n",
    "\n",
    "D. Cả ba đáp án trên."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "D. Cả ba đáp án trên."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PbcBUzP2NN7t"
   },
   "source": [
    "# II. Thực hành"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cx9tmI6Rh9ow"
   },
   "source": [
    "Câu 6: Thực hành phân loại văn bản dựa trên phương pháp bag-of-word và tf-idf đối với bộ dữ liệu [10Topics](https://github.com/duyvuleo/VNTC/tree/master/Data/10Topics/Ver1.1).\n",
    "\n",
    "Gợi ý: Bạn cần thực hiện theo các bước sau đây:\n",
    "\n",
    "- Bước 1: Download dữ liệu.\n",
    "\n",
    "- Bước 2: Tiền xử lý dữ liệu (`Data pre-processing`). Sử dụng phương pháp `bag-of-word` để mã hóa văn bản thành véc tơ.\n",
    "\n",
    "- Bước 3: Phân chia tập `train/validation` và huấn luyện mô hình."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0OmlqOQsgBLj"
   },
   "source": [
    "**Download Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23144,
     "status": "ok",
     "timestamp": 1634875073335,
     "user": {
      "displayName": "khanhblog AI",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhNCi9Qnch9sWXSuvX4N5yijAGEjX1IvfmN-95m=s64",
      "userId": "06481533334230032014"
     },
     "user_tz": -420
    },
    "id": "ut2qRW08IxhL",
    "outputId": "7cfc566a-e6f3-46d4-9fd8-adcfff223576"
   },
   "outputs": [],
   "source": [
    "# Google drive mount point\n",
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7D1CUbk9Jc3S"
   },
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.chdir('drive/MyDrive/Colab Notebooks/ML-Handson-With-Python2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\nguye\\\\Documents\\\\ML HAndson'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "oHwSQ74qItNe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget Test_Full.rar \\\n",
    "&& unrar x Test_Full.rar \\\n",
    "&& rm -f Test_Full.rar && ls Test_Full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "eg8fYSRLKjgn"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCsDLGvoRpww"
   },
   "source": [
    "**Data preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MN1w4FRbgGct"
   },
   "source": [
    "**Model training**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jm9A9XGGlG8y"
   },
   "source": [
    "Câu 7: Thực hành biến đổi dữ liệu với python\n",
    "\n",
    "- Lấy ra current date và current time\n",
    "- Current year\n",
    "- Month of year\n",
    "- Week number of the year\n",
    "- Weekday of the week\n",
    "- Day of year\n",
    "- Day of the month\n",
    "- Day of week\n",
    "\n",
    "\n",
    "Gợi ý: Sử dụng package datetime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gFSYMMKuqRiC"
   },
   "source": [
    "Câu 8: Sử dụng AutoEncoder để giảm chiều bộ dữ liệu sau từ 50 chiều về 10 chiều.\n",
    "Code khởi tạo dữ liệu:\n",
    "\n",
    "```\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Khởi tạo dữ liệu example\n",
    "X, y = make_classification(n_samples=500, n_features=50, random_state=123)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-8kTPQszSfoe"
   },
   "source": [
    "Câu 9: Xây dựng mô hình phân loại trên 10 biến trong không gian giảm chiều và đánh giá độ chính xác mô hình."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nQWhaLPWqnHR"
   },
   "source": [
    "Câu 10: Sử dụng các kĩ thuật lựa chọn đặc trưng khác nhau để lựa chọn ra 10 biến đầu vào từ 50 biến đầu vào gốc. Xây dựng mô hình phân loại trên các biến được lựa chọn và đánh giá độ chính xác."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Main index falls at year-end session\\n\\nThe HCMC bourse faced gloomy trade in the last session of 2019, witnessing the VN-Index fall 4.04 points to end the year at 960.99 on December 31 due to heavy sell-offs and cautious investor sentiment.\\n\\nOn the HCMC market, market breadth was negative as losers outnumbered gainers by 199 to 137. The main index lost 0.42% against the session earlier. There were 182.24 million shares worth VND3 trillion changing hands, up 4.2% in volume, but down 1.6% in value versus the day earlier. Block deals accounted for more than 40 million shares valued at VND859 billion.\\n\\nConstruction firm ROS continued its downward spiral, closing the session down 6.9%, piling pressure on the southern exchange.\\n\\nSome bank stocks, such as VCB, STB, MBB and CTG, lost steam, while others picked up slightly and lender HDB soared by 2.4% to close at the intraday high.\\n\\nAmong blue-chip stocks, property firm NVL and carrier VJC added over 1%, while real estate firm VHM, brewer SAB, retailer VRE and consumer goods firm MSN ended the session down.\\n\\nGas firm GAS tumbled by 2.8%, while others, such as property developer VIC, dairy firm VNM and mobile phone retailer MWG, stood at their reference prices.\\n\\nMost of the speculative stocks, including real estate firms DLG, DRH and HQC, and agricultural chemical firm HAI, closed deep in the red.\\n\\nMeanwhile, property developer FLC bucked the trend, inching up 0.4% and seeing over six million shares traded.\\n\\nOn the Hanoi market, strong demand pushed up the HNX-Index in the last session of the year. The index improved 0.35 points, or 0.34%, against the session earlier, at 102.51. Trade volume totaled 25.8 million shares worth VND287.7 billion.\\n\\nThe rallies of many blue chips, such as lenders ACB and SHB, insurer PVI and property firm DTD, sent the HNX-Index up. SHB still led the northern market by liquidity, with 3.9 million shares changing hands.\\n\\nForeign investors shifted to the selling side in the last session of 2019 after three consecutive sessions of net buying, dragging down the VN-Index. They net sold VND135.5 billion worth of 3.06 million shares, mainly ROS and VIC.\\n\\nOn the northern market, foreigners’ net selling value amounted to VND 4.4 billion worth of over 357,690 shares, up 3.5-fold from the session earlier.\\n\\nsaigontimes'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example 1\n",
    "f = open('01_01_2020.txt', encoding='utf8').read()\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "454"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "tknzr = TweetTokenizer(strip_handles=True)\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()\n",
    "\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "f_tokenize = tknzr.tokenize(f.lower())\n",
    "f_stem = []\n",
    "for element in f_tokenize:\n",
    "    f_stem.append(wnl.lemmatize(element))\n",
    "len(f_stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "445"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_stem_no_integers = [item for item in f_stem if not item.isdigit()]\n",
    "len(f_stem_no_integers) #bỏ những ký tự số"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x218 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 218 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# Tính tfidf cho mỗi từ. max_df để loại bỏ stopwords xuất hiện ở hơn 90% các câu\n",
    "vectorizer = TfidfVectorizer()\n",
    "# Tokenize các câu theo tfidf\n",
    "X = vectorizer.fit_transform([f])\n",
    "#print(vectorizer.get_feature_names())\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>04</th>\n",
       "      <td>0.022559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>06</th>\n",
       "      <td>0.022559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.022559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.022559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>0.022559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>while</th>\n",
       "      <td>0.067677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>with</th>\n",
       "      <td>0.022559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>witnessing</th>\n",
       "      <td>0.022559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>worth</th>\n",
       "      <td>0.090236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>0.067677</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>218 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               tfidf\n",
       "04          0.022559\n",
       "06          0.022559\n",
       "102         0.022559\n",
       "137         0.022559\n",
       "182         0.022559\n",
       "...              ...\n",
       "while       0.067677\n",
       "with        0.022559\n",
       "witnessing  0.022559\n",
       "worth       0.090236\n",
       "year        0.067677\n",
       "\n",
       "[218 rows x 1 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(X.T.todense(), index=vectorizer.get_feature_names(), columns=[\"tfidf\"]) \n",
    "df.sort_values(by=[\"tfidf\"],ascending=False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06767682521924123"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc['year'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'year' in df.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_score_pos_tag (f_stem, df):\n",
    "    pos_score = neg_score = token_count = obj_score = 0\n",
    "    for word in f_stem:\n",
    "        tag = nltk.pos_tag([word])\n",
    "        synst = None\n",
    "        if 'NN' in tag[0] and list(swn.senti_synsets(word, 'n')):\n",
    "            synst = list(swn.senti_synsets(word, 'n'))[0]\n",
    "        elif 'VB' in tag[0] and list(swn.senti_synsets(word, 'v')):\n",
    "            synst = list(swn.senti_synsets(word, 'v'))[0]\n",
    "        elif 'JJ' in tag[0] and list(swn.senti_synsets(word, 'a')):\n",
    "            synst = list(swn.senti_synsets(word, 'a'))[0]\n",
    "        elif 'RB' in tag[0] and list(swn.senti_synsets(word, 'r')):\n",
    "            synst = list(swn.senti_synsets(word, 'r'))[0]\n",
    "          \n",
    "        if synst:\n",
    "            token_count += 1\n",
    "            if word in df.index.tolist():\n",
    "                pos_score += synst.pos_score()* df.loc[word].values[0]\n",
    "                neg_score += synst.neg_score()* df.loc[word].values[0]\n",
    "                obj_score += synst.obj_score()* df.loc[word].values[0]\n",
    "                \n",
    "            else:\n",
    "                pos_score += synst.pos_score()\n",
    "                neg_score += synst.neg_score()\n",
    "                obj_score += synst.obj_score()\n",
    "                \n",
    "        \n",
    "    score_dict = {'positive_score': pos_score, 'negative_score': neg_score,\n",
    "                       'objectivity_score': obj_score,'token_count': token_count}\n",
    "    return score_dict "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tính sentiment scores của 1 bài báo bằng tổng (sentiment score của từng token * tfidf của từng token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'positive_score': 1.823316560654178,\n",
       " 'negative_score': 0.5723907402227868,\n",
       " 'objectivity_score': 32.23696082199501,\n",
       " 'token_count': 161}"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_score_pos_tag (f_stem_no_integers,df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Điểm số nếu không tính tdidf thể hiện tốt hơn xu hướng của bài viết: negative score > positive score \n",
    "{'positive_score': 4.25, 'negative_score': 5.375, 'objectivity_score': 151.375, 'token_count': 161}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>file_name</th>\n",
       "      <th>positive_score</th>\n",
       "      <th>negative_score</th>\n",
       "      <th>objectivity_score</th>\n",
       "      <th>token_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>01_01_202001_01_2020_101_01_2020_201_01_2020_3...</td>\n",
       "      <td>96.500</td>\n",
       "      <td>65.375</td>\n",
       "      <td>2311.125</td>\n",
       "      <td>2473.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>01_02_202001_02_2020_101_02_2020_201_02_2020_3</td>\n",
       "      <td>114.875</td>\n",
       "      <td>63.125</td>\n",
       "      <td>1700.000</td>\n",
       "      <td>1878.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>01_03_202001_03_2020_101_03_2020_201_03_2020_3...</td>\n",
       "      <td>51.125</td>\n",
       "      <td>39.500</td>\n",
       "      <td>921.375</td>\n",
       "      <td>1012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>01_04_202001_04_2020_101_04_2020_201_04_2020_3...</td>\n",
       "      <td>61.500</td>\n",
       "      <td>37.625</td>\n",
       "      <td>1387.875</td>\n",
       "      <td>1487.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>01_05_2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>2021-06-26</td>\n",
       "      <td>06_26_202106_26_2021_106_26_2021_2</td>\n",
       "      <td>50.125</td>\n",
       "      <td>25.750</td>\n",
       "      <td>910.125</td>\n",
       "      <td>986.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>06_27_2021</td>\n",
       "      <td>3.375</td>\n",
       "      <td>3.375</td>\n",
       "      <td>100.250</td>\n",
       "      <td>107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>2021-06-28</td>\n",
       "      <td>06_28_202106_28_2021_106_28_2021_206_28_2021_3</td>\n",
       "      <td>37.625</td>\n",
       "      <td>26.375</td>\n",
       "      <td>725.000</td>\n",
       "      <td>789.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>2021-06-29</td>\n",
       "      <td>06_29_202106_29_2021_106_29_2021_206_29_2021_3...</td>\n",
       "      <td>73.875</td>\n",
       "      <td>46.250</td>\n",
       "      <td>1662.875</td>\n",
       "      <td>1783.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>06_30_202106_30_2021_106_30_2021_206_30_2021_3...</td>\n",
       "      <td>26.125</td>\n",
       "      <td>19.250</td>\n",
       "      <td>658.625</td>\n",
       "      <td>704.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>547 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    publish_date                                          file_name  \\\n",
       "0     2020-01-01  01_01_202001_01_2020_101_01_2020_201_01_2020_3...   \n",
       "1     2020-01-02     01_02_202001_02_2020_101_02_2020_201_02_2020_3   \n",
       "2     2020-01-03  01_03_202001_03_2020_101_03_2020_201_03_2020_3...   \n",
       "3     2020-01-04  01_04_202001_04_2020_101_04_2020_201_04_2020_3...   \n",
       "4     2020-01-05                                         01_05_2020   \n",
       "..           ...                                                ...   \n",
       "542   2021-06-26                 06_26_202106_26_2021_106_26_2021_2   \n",
       "543   2021-06-27                                         06_27_2021   \n",
       "544   2021-06-28     06_28_202106_28_2021_106_28_2021_206_28_2021_3   \n",
       "545   2021-06-29  06_29_202106_29_2021_106_29_2021_206_29_2021_3...   \n",
       "546   2021-06-30  06_30_202106_30_2021_106_30_2021_206_30_2021_3...   \n",
       "\n",
       "     positive_score  negative_score  objectivity_score  token_count  \n",
       "0            96.500          65.375           2311.125       2473.0  \n",
       "1           114.875          63.125           1700.000       1878.0  \n",
       "2            51.125          39.500            921.375       1012.0  \n",
       "3            61.500          37.625           1387.875       1487.0  \n",
       "4               NaN             NaN                NaN          NaN  \n",
       "..              ...             ...                ...          ...  \n",
       "542          50.125          25.750            910.125        986.0  \n",
       "543           3.375           3.375            100.250        107.0  \n",
       "544          37.625          26.375            725.000        789.0  \n",
       "545          73.875          46.250           1662.875       1783.0  \n",
       "546          26.125          19.250            658.625        704.0  \n",
       "\n",
       "[547 rows x 6 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "economy = pd.read_table('economy_daily_sentiment_score', sep=',')\n",
    "economy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "def parser(x):\n",
    "    return datetime.strptime(x, '%Y-%m-%d')\n",
    "economy['publish_date'] = economy['publish_date'].map(lambda x: parser(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Wednesday\n",
       "1       Thursday\n",
       "2         Friday\n",
       "3       Saturday\n",
       "4         Sunday\n",
       "         ...    \n",
       "542     Saturday\n",
       "543       Sunday\n",
       "544       Monday\n",
       "545      Tuesday\n",
       "546    Wednesday\n",
       "Name: weekday, Length: 547, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "economy['weekday'] = economy['publish_date'].apply(lambda x: x.date().strftime('%A'))\n",
    "economy['weekday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       (2020, 1, 3)\n",
       "1       (2020, 1, 4)\n",
       "2       (2020, 1, 5)\n",
       "3       (2020, 1, 6)\n",
       "4       (2020, 1, 7)\n",
       "           ...      \n",
       "542    (2021, 25, 6)\n",
       "543    (2021, 25, 7)\n",
       "544    (2021, 26, 1)\n",
       "545    (2021, 26, 2)\n",
       "546    (2021, 26, 3)\n",
       "Name: year_week_weekday, Length: 547, dtype: object"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "economy['year_week_weekday'] = economy['publish_date'].apply(lambda x: x.date().isocalendar())\n",
    "economy['year_week_weekday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>file_name</th>\n",
       "      <th>positive_score</th>\n",
       "      <th>negative_score</th>\n",
       "      <th>objectivity_score</th>\n",
       "      <th>token_count</th>\n",
       "      <th>weekday</th>\n",
       "      <th>year_week_weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>01_01_202001_01_2020_101_01_2020_201_01_2020_3...</td>\n",
       "      <td>96.500</td>\n",
       "      <td>65.375</td>\n",
       "      <td>2311.125</td>\n",
       "      <td>2473.0</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>(2020, 1, 3)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-02</td>\n",
       "      <td>01_02_202001_02_2020_101_02_2020_201_02_2020_3</td>\n",
       "      <td>114.875</td>\n",
       "      <td>63.125</td>\n",
       "      <td>1700.000</td>\n",
       "      <td>1878.0</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>(2020, 1, 4)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-03</td>\n",
       "      <td>01_03_202001_03_2020_101_03_2020_201_03_2020_3...</td>\n",
       "      <td>51.125</td>\n",
       "      <td>39.500</td>\n",
       "      <td>921.375</td>\n",
       "      <td>1012.0</td>\n",
       "      <td>Friday</td>\n",
       "      <td>(2020, 1, 5)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-01-04</td>\n",
       "      <td>01_04_202001_04_2020_101_04_2020_201_04_2020_3...</td>\n",
       "      <td>61.500</td>\n",
       "      <td>37.625</td>\n",
       "      <td>1387.875</td>\n",
       "      <td>1487.0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>(2020, 1, 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-01-05</td>\n",
       "      <td>01_05_2020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>(2020, 1, 7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>2021-06-26</td>\n",
       "      <td>06_26_202106_26_2021_106_26_2021_2</td>\n",
       "      <td>50.125</td>\n",
       "      <td>25.750</td>\n",
       "      <td>910.125</td>\n",
       "      <td>986.0</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>(2021, 25, 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>2021-06-27</td>\n",
       "      <td>06_27_2021</td>\n",
       "      <td>3.375</td>\n",
       "      <td>3.375</td>\n",
       "      <td>100.250</td>\n",
       "      <td>107.0</td>\n",
       "      <td>Sunday</td>\n",
       "      <td>(2021, 25, 7)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>2021-06-28</td>\n",
       "      <td>06_28_202106_28_2021_106_28_2021_206_28_2021_3</td>\n",
       "      <td>37.625</td>\n",
       "      <td>26.375</td>\n",
       "      <td>725.000</td>\n",
       "      <td>789.0</td>\n",
       "      <td>Monday</td>\n",
       "      <td>(2021, 26, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>2021-06-29</td>\n",
       "      <td>06_29_202106_29_2021_106_29_2021_206_29_2021_3...</td>\n",
       "      <td>73.875</td>\n",
       "      <td>46.250</td>\n",
       "      <td>1662.875</td>\n",
       "      <td>1783.0</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>(2021, 26, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>2021-06-30</td>\n",
       "      <td>06_30_202106_30_2021_106_30_2021_206_30_2021_3...</td>\n",
       "      <td>26.125</td>\n",
       "      <td>19.250</td>\n",
       "      <td>658.625</td>\n",
       "      <td>704.0</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>(2021, 26, 3)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>547 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    publish_date                                          file_name  \\\n",
       "0     2020-01-01  01_01_202001_01_2020_101_01_2020_201_01_2020_3...   \n",
       "1     2020-01-02     01_02_202001_02_2020_101_02_2020_201_02_2020_3   \n",
       "2     2020-01-03  01_03_202001_03_2020_101_03_2020_201_03_2020_3...   \n",
       "3     2020-01-04  01_04_202001_04_2020_101_04_2020_201_04_2020_3...   \n",
       "4     2020-01-05                                         01_05_2020   \n",
       "..           ...                                                ...   \n",
       "542   2021-06-26                 06_26_202106_26_2021_106_26_2021_2   \n",
       "543   2021-06-27                                         06_27_2021   \n",
       "544   2021-06-28     06_28_202106_28_2021_106_28_2021_206_28_2021_3   \n",
       "545   2021-06-29  06_29_202106_29_2021_106_29_2021_206_29_2021_3...   \n",
       "546   2021-06-30  06_30_202106_30_2021_106_30_2021_206_30_2021_3...   \n",
       "\n",
       "     positive_score  negative_score  objectivity_score  token_count  \\\n",
       "0            96.500          65.375           2311.125       2473.0   \n",
       "1           114.875          63.125           1700.000       1878.0   \n",
       "2            51.125          39.500            921.375       1012.0   \n",
       "3            61.500          37.625           1387.875       1487.0   \n",
       "4               NaN             NaN                NaN          NaN   \n",
       "..              ...             ...                ...          ...   \n",
       "542          50.125          25.750            910.125        986.0   \n",
       "543           3.375           3.375            100.250        107.0   \n",
       "544          37.625          26.375            725.000        789.0   \n",
       "545          73.875          46.250           1662.875       1783.0   \n",
       "546          26.125          19.250            658.625        704.0   \n",
       "\n",
       "       weekday year_week_weekday  \n",
       "0    Wednesday      (2020, 1, 3)  \n",
       "1     Thursday      (2020, 1, 4)  \n",
       "2       Friday      (2020, 1, 5)  \n",
       "3     Saturday      (2020, 1, 6)  \n",
       "4       Sunday      (2020, 1, 7)  \n",
       "..         ...               ...  \n",
       "542   Saturday     (2021, 25, 6)  \n",
       "543     Sunday     (2021, 25, 7)  \n",
       "544     Monday     (2021, 26, 1)  \n",
       "545    Tuesday     (2021, 26, 2)  \n",
       "546  Wednesday     (2021, 26, 3)  \n",
       "\n",
       "[547 rows x 8 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "economy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
