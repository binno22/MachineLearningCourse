{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cNj0WtkDb_tw"
   },
   "source": [
    "# I. Thực hành\n",
    "Các đáp án được lựa chọn sẽ được tô đậm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V71cW0PFNWoO"
   },
   "source": [
    "Câu 1: Trong phương pháp bag-of-word thì mỗi một đoạn văn bản sẽ được biến đổi thành véc tơ đặc trưng như thế nào?\n",
    "\n",
    "\n",
    "**A. Thành véc tơ tần suất của các từ xuất hiện trong từ điển.**\n",
    "\n",
    "B. Thành véc tơ one-hot, từ nào xuất hiện trong văn bản thì có giá trị 1, trái lại nhận giá trị 0.\n",
    "\n",
    "C. Thành véc tơ tf-idf của từ.\n",
    "\n",
    "D. Thành một véc tơ trong không gian latent space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-bFR4B-1dv0_"
   },
   "source": [
    "Câu 2: Hai phương pháp `bigram` và `trigram` trong `bag-of-n-gram` sẽ mã hoá một văn bản như thế nào?\n",
    "\n",
    "A. `Bigram` sẽ ghép ba từ liên tiếp thành một token. `Trigram` sẽ ghép hai từ liên tiếp nhau thành một token.\n",
    "\n",
    "**B. `Bigram` sẽ ghép hai từ liên tiếp thành một token. `Trigram` sẽ ghép ba từ liên tiếp nhau thành một token.**\n",
    "\n",
    "C. `Bigram` sẽ chia mỗi một từ thành một token. `Trigram` sẽ ghép ba từ liên tiếp nhau thành một token.\n",
    "\n",
    "D. `Bigram` sẽ ghép hai từ bất kì trong khoảng cách gần thành một token. `Trigram` sẽ ghép ba từ liên tiếp trong khoảng cách gần thành một token."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uqu9GnNDfG_0"
   },
   "source": [
    "Câu 3: Giải thích ý nghĩa của chỉ số tf-idf được sử dụng để mã hoá các từ trong bộ văn bản. Một từ có tf-idf cao thì chứng tỏ điều gì?\n",
    "\n",
    "A. `tf-idf` là chỉ số mã hóa dựa trên độ dài của văn bản. Khi `tf-idf` cao chứng tỏ mức độ phổ biến của từ càng cao và ngược lại.\n",
    "\n",
    "B. `tf-idf` là chỉ số mã hóa dựa trên tần suất. Khi `tf-idf` cao chứng tỏ mức độ phổ biến của từ càng thấp và ngược lại.\n",
    "\n",
    "**C. `tf-idf` nhằm đánh giá mức độ phổ biến của một từ dựa vào tần suất xuất hiện của từ trong một văn bản và tần suất các văn bản xuất hiện từ đó. Khi `tf-idf` cao chứng tỏ mức độ phổ biến của từ càng cao và ngược lại.**\n",
    "\n",
    "D. `tf-idf` nhằm đánh giá mức độ quan trọng của một từ dựa vào tần suất xuất hiện của từ trong một văn bản và tần suất các văn bản xuất hiện từ đó. Khi `tf-idf` cao chứng tỏ mức độ quan trọng của từ càng cao và ngược lại."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qHA9G2YlNcnG"
   },
   "source": [
    "Câu 4: Kiến trúc nào thường được sử dụng để trích xuất đặc trưng (`Feature Extractor`) trong các bộ dữ liệu ảnh:\n",
    "\n",
    "A. Thuật toán SVM\n",
    " \n",
    "B. Thuật toán MLP\n",
    "\n",
    "**C. Thuật toán CNN**\n",
    "\n",
    "D. Thuật toán LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BA3ZjsDxPR8T"
   },
   "source": [
    "Câu 5: Tại sao chúng ta cần thực hiện các kĩ thuật chuẩn hóa dữ liệu như `Min-max Scaling`, `Standardization Scaling`, hoặc `Unit length Scaling` trên dữ liệu $\\mathbf{X}$ trước khi huấn luyện mô hình:\n",
    "\n",
    "A. Để đồng nhất đơn vị của các biến trước khi huấn luyện mô hình.\n",
    "\n",
    "B. Giúp các thuật toán ổn định hơn.\n",
    "\n",
    "C. Giảm chi phí tính toán.\n",
    "\n",
    "**D. Cả ba đáp án trên.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PbcBUzP2NN7t"
   },
   "source": [
    "# II. Thực hành"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cx9tmI6Rh9ow"
   },
   "source": [
    "Câu 6: Thực hành phân loại văn bản dựa trên phương pháp bag-of-word và tf-idf đối với bộ dữ liệu [10Topics](https://github.com/duyvuleo/VNTC/tree/master/Data/10Topics/Ver1.1).\n",
    "\n",
    "Gợi ý: Bạn cần thực hiện theo các bước sau đây:\n",
    "\n",
    "- Bước 1: Download dữ liệu.\n",
    "\n",
    "- Bước 2: Tiền xử lý dữ liệu (`Data pre-processing`). Sử dụng phương pháp `bag-of-word` để mã hóa văn bản thành véc tơ.\n",
    "\n",
    "- Bước 3: Phân chia tập `train/validation` và huấn luyện mô hình."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0OmlqOQsgBLj"
   },
   "source": [
    "**Download Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ut2qRW08IxhL",
    "outputId": "37f5ac41-e6f8-41d5-f083-f72eba17b378"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "# Google drive mount point\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7D1CUbk9Jc3S"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('drive/MyDrive/Colab Notebooks/Buổi 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oHwSQ74qItNe"
   },
   "outputs": [],
   "source": [
    "#!wget https://raw.githubusercontent.com/duyvuleo/VNTC/master/Data/10Topics/Ver1.1/Test_Full.rar \\\n",
    "#&& unrar x Test_Full.rar \\\n",
    "#&& rm -f Test_Full.rar && ls Test_Full\n",
    "\n",
    "#chỉ chạy code này một lần"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OzKiQX035xvy"
   },
   "outputs": [],
   "source": [
    "#!wget https://raw.githubusercontent.com/duyvuleo/VNTC/master/Data/10Topics/Ver1.1/Train_Full.rar \\\n",
    "#&& unrar x Train_Full.rar \\\n",
    "#&& rm -f Train_Full.rar && ls Train_Full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eg8fYSRLKjgn"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QCsDLGvoRpww"
   },
   "source": [
    "**Data preprocessing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nHhDtdKZqEhT"
   },
   "source": [
    "Tham khảo: https://medium.com/analytics-vidhya/text-classification-from-bag-of-words-to-bert-1e628a2dd4c9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tlMUjU5Q549_"
   },
   "outputs": [],
   "source": [
    "def from_list_to_sentence(sentences):  #transform a text to a sentence\n",
    "  res_ = ''\n",
    "  for sentence in sentences:\n",
    "    sentence.replace('\\n',' ') #remove endline character\n",
    "    res_ = res_ + sentence\n",
    "  return res_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5KiVGta1ZAAx"
   },
   "outputs": [],
   "source": [
    "#query every file in the directory Train_Full\n",
    "all_texts = []\n",
    "for root, dirs, files in os.walk(\"./Train_Full\", topdown=True):\n",
    "  for file in files:\n",
    "    file_path = root +'/' + file\n",
    "    sentences = open(file_path,'r', encoding = 'utf-16').readlines() #a list of all sentences in a file\n",
    "    all_texts.append(from_list_to_sentence(sentences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "br1nM0Ii7Q_X"
   },
   "outputs": [],
   "source": [
    "#all_texts chứa tất cả các file văn bản, trong đó mỗi văn bản sẽ được lưu trữ là một phần tử.\n",
    "\n",
    "vect = CountVectorizer()\n",
    "X = vect.fit_transform(all_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MN1w4FRbgGct"
   },
   "source": [
    "**Model training** bỏ qua"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jm9A9XGGlG8y"
   },
   "source": [
    "Câu 7: Thực hành biến đổi dữ liệu với python\n",
    "\n",
    "- Lấy ra current date và current time\n",
    "- Current year\n",
    "- Month of year\n",
    "- Week number of the year\n",
    "- Weekday of the week\n",
    "- Day of year\n",
    "- Day of the month\n",
    "- Day of week\n",
    "\n",
    "\n",
    "Gợi ý: Sử dụng package datetime."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aXiRYwOHlbZD",
    "outputId": "40257991-886e-4d46-958b-73afaffcfd1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "current date:  2022-12-09\n",
      "current time:  00:17:34.445449\n",
      "current year: 2022\n",
      "month of year: 12\n",
      "Week number of the year:  49\n",
      "Weekday of the week:  5\n",
      "Day of the year:  343\n",
      "Day of the month:  9\n",
      "Day of the week:  5\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime \n",
    "import pytz\n",
    "now = datetime.now(pytz.timezone('Asia/Saigon'))\n",
    "#lấy ra current date và current time\n",
    "print('current date: ',now.date())\n",
    "print('current time: ',now.time())\n",
    "\n",
    "#lấy ra current year \n",
    "print('current year:',now.year)\n",
    "\n",
    "#lấy ra month of year \n",
    "print('month of year:',now.month)\n",
    "\n",
    "#lấy ra week number of the year\n",
    "print('Week number of the year: ', now.isocalendar()[1])\n",
    "\n",
    "#lấy ra weekday of the week\n",
    "print('Weekday of the week: ', now.isocalendar()[2])\n",
    "\n",
    "#lấy ra day of the year\n",
    "print('Day of the year: ', now.timetuple().tm_yday)\n",
    "\n",
    "#lấy ra day of the month\n",
    "print('Day of the month: ', now.day)\n",
    "\n",
    "#lấy ra day of week\n",
    "print('Day of the week: ', now.isoweekday())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gFSYMMKuqRiC"
   },
   "source": [
    "Câu 8: Sử dụng AutoEncoder để giảm chiều bộ dữ liệu sau từ 50 chiều về 10 chiều.\n",
    "Code khởi tạo dữ liệu:\n",
    "\n",
    "```\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Khởi tạo dữ liệu example\n",
    "X, y = make_classification(n_samples=500, n_features=50, random_state=123)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7IW9DBESuS7v"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "\n",
    "# Khởi tạo dữ liệu example\n",
    "X, y = make_classification(n_samples=500, n_features=50, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gPb3fGYpudaO"
   },
   "outputs": [],
   "source": [
    "#import packages for AutoEncoder, reference: https://www.kaggle.com/code/saivarunk/dimensionality-reduction-using-keras-auto-encoder/notebook\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E_Oyiaxs8aLc"
   },
   "outputs": [],
   "source": [
    "n_features = X.shape[1] #original number of features = 50\n",
    "encoded_features = 10\n",
    "input_dim = Input(shape = (n_features, ))\n",
    "\n",
    "# Encoder Layers: 2 layers, from 50 to 30 and from 30 to 10\n",
    "encoded1 = Dense(30, activation = 'relu')(input_dim)\n",
    "encoded2 = Dense(encoded_features, activation = 'relu')(encoded1)\n",
    "\n",
    "# Decoder Layers\n",
    "decoded1 = Dense(30, activation = 'relu')(encoded2)\n",
    "decoded2 = Dense(n_features, activation = 'relu')(decoded1)\n",
    "\n",
    "# Combine Encoder and Decoder Layers\n",
    "autoencoder = Model(inputs = input_dim, outputs = decoded2)\n",
    "\n",
    "# Compile the Model\n",
    "autoencoder.compile(optimizer = 'adadelta', loss = 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V5wTGaBXAzjR",
    "outputId": "d775bb2e-484b-49f9-e669-3cb291d58475"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "encoder = Model(inputs = input_dim, outputs = encoded2)\n",
    "encoded_input = Input(shape = (encoded_features, ))\n",
    "\n",
    "encoded_X = encoder.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8d3JXLBvCUau",
    "outputId": "01d19cc5-e207-4e07-f065-40ffb905aaac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#số chiều của encoded_X sau khi giảm chiều dữ liệu\n",
    "encoded_X.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-8kTPQszSfoe"
   },
   "source": [
    "Câu 9: Xây dựng mô hình phân loại trên 10 biến trong không gian giảm chiều và đánh giá độ chính xác mô hình."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E20r_YYiHXm9"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gimeFKCPE_NA",
    "outputId": "523e6e02-32be-4ca0-8b77-dd3c5584b68d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean F1: 0.525 0.063\n"
     ]
    }
   ],
   "source": [
    "#tạo folds, chọn mô hình\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "lr = LogisticRegression()\n",
    "#tạo metrics\n",
    "metric = make_scorer(f1_score)\n",
    "# Đánh giá mô hình\n",
    "scores = cross_val_score(lr, encoded_X, y, scoring=metric, cv=cv) #không có n_jobs vì chỉ chạy 1 job 1 lần, tránh quá tải\n",
    "print('Mean F1: {:.03f} {:.03f}'.format(np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nQWhaLPWqnHR"
   },
   "source": [
    "Câu 10: Sử dụng các kĩ thuật lựa chọn đặc trưng khác nhau để lựa chọn ra 10 biến đầu vào từ 50 biến đầu vào gốc. Xây dựng mô hình phân loại trên các biến được lựa chọn và đánh giá độ chính xác."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7RzHrYb2HhJQ",
    "outputId": "a9a4ae99-a95a-45b1-aca1-2c25c7e2cd1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 10\n",
      "Mean F1: 0.904 0.050\n"
     ]
    }
   ],
   "source": [
    "#sử dụng kỹ thuật lựa chọn đặc trưng dựa trên phương sai\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "#loại bỏ các biến có phương sai nhỏ hơn 1.075, có 10 features tất cả\n",
    "X_kvar = VarianceThreshold(1.075).fit_transform(X)\n",
    "print('Number of features: {}'.format(X_kvar.shape[1]))\n",
    "\n",
    "# Đánh giá mô hình\n",
    "scores = cross_val_score(lr, X_kvar, y, scoring=metric, cv=cv) \n",
    "print('Mean F1: {:.03f} {:.03f}'.format(np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fxxBFTZGHzD9",
    "outputId": "e8124d22-4f18-4869-c829-151302f59335"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape after applying statistical selection:  (500, 10)\n",
      "Mean F1: 0.894 0.055\n"
     ]
    }
   ],
   "source": [
    "#sử dụng kỹ thuật lựa chọn đặc trưng dựa trên chỉ số của phân phối chi-square và phương pháp Fisher\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "X_kbest_fisher = SelectKBest(f_classif, k = 10).fit_transform(X, y)\n",
    "print('X shape after applying statistical selection: ',X_kbest_fisher.shape)\n",
    "scores = cross_val_score(lr, X_kbest_fisher, y, scoring=metric, cv=cv)\n",
    "print('Mean F1: {:.03f} {:.03f}'.format(np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7vrWnl5HKR5w"
   },
   "outputs": [],
   "source": [
    "#Có 50 features ban đầu, cần lựa chọn ra 10 features, số tổ hợp cần duyệt để lựa chọn mô hình là 50C10 ~ 3.73e16 => không dùng ở đây"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L1ocfyuSON6_",
    "outputId": "b22d4e2e-1c34-45e9-f813-f6ebc1658524"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: mlxtend in /usr/local/lib/python3.8/dist-packages (0.14.0)\n",
      "Requirement already satisfied: scipy>=0.17 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (1.7.3)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (1.0.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from mlxtend) (57.4.0)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (1.21.6)\n",
      "Requirement already satisfied: pandas>=0.17.1 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (1.3.5)\n",
      "Requirement already satisfied: matplotlib>=1.5.1 in /usr/local/lib/python3.8/dist-packages (from mlxtend) (3.2.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5.1->mlxtend) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5.1->mlxtend) (1.4.4)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5.1->mlxtend) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib>=1.5.1->mlxtend) (0.11.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=0.17.1->mlxtend) (2022.6)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.1->matplotlib>=1.5.1->mlxtend) (1.15.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.18->mlxtend) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.8/dist-packages (from scikit-learn>=0.18->mlxtend) (1.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TDgwNGE3NUMW",
    "outputId": "591d1263-3b04-4967-bdef-99cba1b3f3c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape after applying SFS:  (500, 10)\n",
      "Mean F1: 0.900 0.052\n"
     ]
    }
   ],
   "source": [
    "#Sử dụng kỹ thuật sequential search\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "\n",
    "selector = SequentialFeatureSelector(lr, scoring = 'f1', \n",
    "                                     n_features_to_select = 10,\n",
    "                                     direction = 'forward',\n",
    "                                     n_jobs = -1)\n",
    "X_sfs = selector.fit_transform(X,y)\n",
    "print('X shape after applying SFS: ',X_sfs.shape)\n",
    "scores = cross_val_score(lr, X_sfs, y, scoring=metric, cv=cv)\n",
    "print('Mean F1: {:.03f} {:.03f}'.format(np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Aj2vtHtVOCmh"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
